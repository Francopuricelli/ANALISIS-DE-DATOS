{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Librerías importadas correctamente ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbac5d",
   "metadata": {},
   "source": [
    "## 1. Cargar y Explorar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceef4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "df_eph = pd.read_parquet(\"../datos/processed/eph_consolidado.parquet\")\n",
    "\n",
    "# Filtrar solo ocupados (tienen ingreso potencial)\n",
    "df_ocupados = df_eph[df_eph['es_ocupado']].copy()\n",
    "\n",
    "print(f\"Total de ocupados: {len(df_ocupados):,}\")\n",
    "print(f\"Dimensiones: {df_ocupados.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d00001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar patrón de no respuesta\n",
    "columnas_ingreso = [col for col in df_ocupados.columns if 'P21' in col or 'P47T' in col]\n",
    "\n",
    "print(\"Columnas de ingreso disponibles:\")\n",
    "for col in columnas_ingreso:\n",
    "    total = len(df_ocupados)\n",
    "    no_nulos = df_ocupados[col].notna().sum()\n",
    "    positivos = (df_ocupados[col] > 0).sum()\n",
    "    tasa_respuesta = (positivos / total) * 100\n",
    "    tasa_no_respuesta = 100 - tasa_respuesta\n",
    "    \n",
    "    print(f\"  {col}:\")\n",
    "    print(f\"    - Total registros: {total:,}\")\n",
    "    print(f\"    - No nulos: {no_nulos:,}\")\n",
    "    print(f\"    - Positivos: {positivos:,}\")\n",
    "    print(f\"    - Tasa de respuesta: {tasa_respuesta:.2f}%\")\n",
    "    print(f\"    - Tasa de no respuesta: {tasa_no_respuesta:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar variable target (ingreso principal o total individual)\n",
    "if 'P21_real' in df_ocupados.columns:\n",
    "    target_col = 'P21_real'\n",
    "elif 'P47T_real' in df_ocupados.columns:\n",
    "    target_col = 'P47T_real'\n",
    "else:\n",
    "    raise ValueError(\"No se encontró columna de ingreso real\")\n",
    "\n",
    "print(f\"Variable target seleccionada: {target_col}\")\n",
    "\n",
    "# Crear variable indicadora de respuesta\n",
    "df_ocupados['tiene_ingreso'] = (df_ocupados[target_col].notna()) & (df_ocupados[target_col] > 0)\n",
    "\n",
    "print(f\"\\nRegistros con ingreso válido: {df_ocupados['tiene_ingreso'].sum():,}\")\n",
    "print(f\"Registros sin ingreso: {(~df_ocupados['tiene_ingreso']).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e9e775",
   "metadata": {},
   "source": [
    "## 2. Preparación de Variables para el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables predictoras disponibles\n",
    "variables_predictoras = {\n",
    "    'CH04': 'Sexo',\n",
    "    'CH06': 'Edad',\n",
    "    'NIVEL_ED': 'Nivel educativo',\n",
    "    'CAT_OCUP': 'Categoría ocupacional',\n",
    "    'PP04B_COD': 'Rama de actividad',\n",
    "    'PP04D_COD': 'Ocupación',\n",
    "    'ANO4': 'Año',\n",
    "    'TRIMESTRE': 'Trimestre',\n",
    "    'REGION': 'Región',\n",
    "    'AGLOMERADO': 'Aglomerado'\n",
    "}\n",
    "\n",
    "# Verificar disponibilidad\n",
    "vars_disponibles = {k: v for k, v in variables_predictoras.items() if k in df_ocupados.columns}\n",
    "\n",
    "print(\"Variables predictoras disponibles:\")\n",
    "for var, desc in vars_disponibles.items():\n",
    "    print(f\"  • {var}: {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59921321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset para modelado (solo registros con ingreso válido)\n",
    "df_model = df_ocupados[df_ocupados['tiene_ingreso']].copy()\n",
    "\n",
    "# Seleccionar variables\n",
    "feature_cols = [col for col in vars_disponibles.keys() if col in df_model.columns]\n",
    "\n",
    "# Preparar X e y\n",
    "X = df_model[feature_cols].copy()\n",
    "y = df_model[target_col].copy()\n",
    "\n",
    "# Logaritmo del ingreso (para normalizar distribución)\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "print(f\"Dataset de modelado:\")\n",
    "print(f\"  Observaciones: {len(X):,}\")\n",
    "print(f\"  Variables predictoras: {len(feature_cols)}\")\n",
    "print(f\"\\nVariables utilizadas: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4135fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar valores faltantes en predictores (con la mediana)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X),\n",
    "    columns=X.columns,\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "print(\"Valores faltantes imputados en predictores ✓\")\n",
    "print(f\"\\nEstadísticas del target (log):\")\n",
    "print(y_log.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5eff9b",
   "metadata": {},
   "source": [
    "## 3. División de Datos: Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en train y test (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {len(X_train):,} observaciones\")\n",
    "print(f\"Conjunto de prueba: {len(X_test):,} observaciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee82d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar variables (importante para Ridge y Lasso)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Datos estandarizados ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8791547",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164da374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de modelos a probar\n",
    "modelos = {\n",
    "    'Regresión Lineal': LinearRegression(),\n",
    "    'Ridge (L2)': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso (L1)': Lasso(alpha=0.1, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Modelos a entrenar:\")\n",
    "for nombre in modelos.keys():\n",
    "    print(f\"  • {nombre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar modelos\n",
    "resultados = []\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nEntrenando: {nombre}...\", end=\" \")\n",
    "    \n",
    "    # Decidir si usar datos escalados o no\n",
    "    if nombre in ['Ridge (L2)', 'Lasso (L1)']:\n",
    "        X_train_usar = X_train_scaled\n",
    "        X_test_usar = X_test_scaled\n",
    "    else:\n",
    "        X_train_usar = X_train\n",
    "        X_test_usar = X_test\n",
    "    \n",
    "    # Entrenar\n",
    "    modelo.fit(X_train_usar, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred_train = modelo.predict(X_train_usar)\n",
    "    y_pred_test = modelo.predict(X_test_usar)\n",
    "    \n",
    "    # Métricas\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    resultados.append({\n",
    "        'Modelo': nombre,\n",
    "        'R² Train': r2_train,\n",
    "        'R² Test': r2_test,\n",
    "        'RMSE Train': rmse_train,\n",
    "        'RMSE Test': rmse_test,\n",
    "        'MAE Test': mae_test\n",
    "    })\n",
    "    \n",
    "    print(f\"✓ (R² Test: {r2_test:.4f})\")\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTADOS DE LOS MODELOS\")\n",
    "print(\"=\"*70)\n",
    "print(df_resultados.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094f6cb",
   "metadata": {},
   "source": [
    "## 5. Evaluación del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar mejor modelo (mayor R² en test)\n",
    "mejor_idx = df_resultados['R² Test'].idxmax()\n",
    "mejor_modelo_nombre = df_resultados.loc[mejor_idx, 'Modelo']\n",
    "mejor_modelo = modelos[mejor_modelo_nombre]\n",
    "\n",
    "print(f\"Mejor modelo: {mejor_modelo_nombre}\")\n",
    "print(f\"R² Test: {df_resultados.loc[mejor_idx, 'R² Test']:.4f}\")\n",
    "print(f\"RMSE Test: {df_resultados.loc[mejor_idx, 'RMSE Test']:.4f}\")\n",
    "print(f\"MAE Test: {df_resultados.loc[mejor_idx, 'MAE Test']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de comparación de modelos\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# R² Score\n",
    "ax1 = axes[0]\n",
    "x_pos = np.arange(len(df_resultados))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x_pos - width/2, df_resultados['R² Train'], width, label='Train', alpha=0.8)\n",
    "ax1.bar(x_pos + width/2, df_resultados['R² Test'], width, label='Test', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Modelo', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('R² Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Comparación de R² por Modelo', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(df_resultados['Modelo'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# RMSE\n",
    "ax2 = axes[1]\n",
    "ax2.bar(x_pos - width/2, df_resultados['RMSE Train'], width, label='Train', alpha=0.8)\n",
    "ax2.bar(x_pos + width/2, df_resultados['RMSE Test'], width, label='Test', alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Modelo', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('RMSE', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Comparación de RMSE por Modelo', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(df_resultados['Modelo'], rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../resultados/graficos/comparacion_modelos_imputacion.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Gráfico guardado: comparacion_modelos_imputacion.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab6092",
   "metadata": {},
   "source": [
    "## 6. Interpretación de Variables (Importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fda2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de variables (si el modelo lo soporta)\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    # Random Forest o Gradient Boosting\n",
    "    importancias = mejor_modelo.feature_importances_\n",
    "    df_importancia = pd.DataFrame({\n",
    "        'Variable': feature_cols,\n",
    "        'Importancia': importancias\n",
    "    }).sort_values('Importancia', ascending=False)\n",
    "    \n",
    "    # Gráfico\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    ax.barh(df_importancia['Variable'], df_importancia['Importancia'], color='steelblue')\n",
    "    ax.set_xlabel('Importancia', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Variable', fontsize=13, fontweight='bold')\n",
    "    ax.set_title(f'Importancia de Variables - {mejor_modelo_nombre}', \n",
    "                fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../resultados/graficos/importancia_variables.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Gráfico guardado: importancia_variables.png\")\n",
    "    print(\"\\nImportancia de variables:\")\n",
    "    print(df_importancia.to_string(index=False))\n",
    "    \n",
    "elif hasattr(mejor_modelo, 'coef_'):\n",
    "    # Regresión lineal, Ridge o Lasso\n",
    "    coeficientes = mejor_modelo.coef_\n",
    "    df_coef = pd.DataFrame({\n",
    "        'Variable': feature_cols,\n",
    "        'Coeficiente': coeficientes\n",
    "    }).sort_values('Coeficiente', key=abs, ascending=False)\n",
    "    \n",
    "    # Gráfico\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    colors = ['green' if c > 0 else 'red' for c in df_coef['Coeficiente']]\n",
    "    ax.barh(df_coef['Variable'], df_coef['Coeficiente'], color=colors, alpha=0.7)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax.set_xlabel('Coeficiente', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Variable', fontsize=13, fontweight='bold')\n",
    "    ax.set_title(f'Coeficientes del Modelo - {mejor_modelo_nombre}', \n",
    "                fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../resultados/graficos/coeficientes_modelo.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Gráfico guardado: coeficientes_modelo.png\")\n",
    "    print(\"\\nCoeficientes del modelo:\")\n",
    "    print(df_coef.to_string(index=False))\n",
    "else:\n",
    "    print(\"El modelo seleccionado no proporciona importancia de variables ni coeficientes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b8370",
   "metadata": {},
   "source": [
    "## 7. Gráfico de Predicciones vs. Valores Reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener predicciones del mejor modelo\n",
    "if mejor_modelo_nombre in ['Ridge (L2)', 'Lasso (L1)']:\n",
    "    y_pred_final = mejor_modelo.predict(X_test_scaled)\n",
    "else:\n",
    "    y_pred_final = mejor_modelo.predict(X_test)\n",
    "\n",
    "# Gráfico de dispersión\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax.scatter(y_test, y_pred_final, alpha=0.3, s=10)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "        'r--', linewidth=2, label='Predicción perfecta')\n",
    "\n",
    "ax.set_xlabel('Log(Ingreso Real)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Log(Ingreso Predicho)', fontsize=13, fontweight='bold')\n",
    "ax.set_title(f'Predicciones vs. Valores Reales - {mejor_modelo_nombre}', \n",
    "            fontsize=15, fontweight='bold', pad=20)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../resultados/graficos/predicciones_vs_reales.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Gráfico guardado: predicciones_vs_reales.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c9bcb8",
   "metadata": {},
   "source": [
    "## 8. Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar tabla de resultados\n",
    "df_resultados.to_csv('../resultados/tablas/resultados_modelos_imputacion.csv', index=False)\n",
    "print(\"✓ Tabla guardada: resultados_modelos_imputacion.csv\")\n",
    "\n",
    "# Guardar importancia/coeficientes\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    df_importancia.to_csv('../resultados/tablas/importancia_variables.csv', index=False)\n",
    "    print(\"✓ Tabla guardada: importancia_variables.csv\")\n",
    "elif hasattr(mejor_modelo, 'coef_'):\n",
    "    df_coef.to_csv('../resultados/tablas/coeficientes_modelo.csv', index=False)\n",
    "    print(\"✓ Tabla guardada: coeficientes_modelo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc167b",
   "metadata": {},
   "source": [
    "## 9. Resumen del Análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESUMEN DEL MODELO DE IMPUTACIÓN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. DATOS\")\n",
    "print(f\"   Total de ocupados: {len(df_ocupados):,}\")\n",
    "print(f\"   Con ingreso válido: {df_ocupados['tiene_ingreso'].sum():,}\")\n",
    "print(f\"   Tasa de respuesta: {(df_ocupados['tiene_ingreso'].sum() / len(df_ocupados)) * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n2. MEJOR MODELO\")\n",
    "print(f\"   Nombre: {mejor_modelo_nombre}\")\n",
    "print(f\"   R² (Test): {df_resultados.loc[mejor_idx, 'R² Test']:.4f}\")\n",
    "print(f\"   RMSE (Test): {df_resultados.loc[mejor_idx, 'RMSE Test']:.4f}\")\n",
    "print(f\"   MAE (Test): {df_resultados.loc[mejor_idx, 'MAE Test']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. INTERPRETACIÓN\")\n",
    "print(f\"   Un R² de {df_resultados.loc[mejor_idx, 'R² Test']:.2%} indica que el modelo explica\")\n",
    "print(f\"   {df_resultados.loc[mejor_idx, 'R² Test']:.2%} de la variabilidad en los ingresos.\")\n",
    "\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    top3 = df_importancia.head(3)\n",
    "    print(f\"\\n   Las 3 variables más importantes son:\")\n",
    "    for i, row in top3.iterrows():\n",
    "        print(f\"     {i+1}. {row['Variable']} (Importancia: {row['Importancia']:.4f})\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Modelo de imputación completado ✓\")\n",
    "print(f\"{'='*70}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
